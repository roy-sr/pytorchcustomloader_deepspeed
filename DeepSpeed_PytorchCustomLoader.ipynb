{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepSpeed_PytorchCustomLoader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1pqIIYYk3wt09hA9nAwXyfcufBEFQbHYT",
      "authorship_tag": "ABX9TyOost0OEvN8Mb10PZkaLHKJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roy-sr/pytorchcustomloader_deepspeed/blob/master/DeepSpeed_PytorchCustomLoader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDe0tueNLk7E",
        "colab_type": "code",
        "outputId": "051fd4d5-1d85-4cbc-a59a-37e1ce1913a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD-QbryBRTvz",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK6uV6aKRVRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import torchvision.datasets.vision\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aODPzJifRsgS",
        "colab_type": "text"
      },
      "source": [
        "**Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_Hee7waRssM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3WCwK1SaIWA",
        "colab_type": "text"
      },
      "source": [
        "**Custom Data Loader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wP6VFVXa4iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def default_image_loader(path):\n",
        "     image = cv2.imread(path)\n",
        "     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "     return image\n",
        "\n",
        "\n",
        "class MNISTCustom_Loader(torchvision.datasets.vision.VisionDataset):\n",
        "    def __init__(self, root, filenames_filename, class_filename, transform=None, target_transform=None):\n",
        "        super(MNISTCustom_Loader, self).__init__(root, transform=transform,target_transform=target_transform)\n",
        "        \"\"\" filenames_filename: A text file with each line containing the path to an image e.g. images/class/sample.jpg\n",
        "            class_filename: A text file with each line containing the class of the image \"\"\"\n",
        "\n",
        "        self.base_path = root  \n",
        "        self.loader = default_image_loader\n",
        "        self.filenamelist = []\n",
        "        for line in open(filenames_filename):\n",
        "            self.filenamelist.append(line.rstrip('\\n'))\n",
        "\n",
        "        self.targets = []\n",
        "        for line in open(class_filename):\n",
        "            self.targets.append(int(line.rstrip('\\n')))   \n",
        "\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        print(\"Loader Intialized Successfully\")\n",
        "      \n",
        "    def __getitem__(self, index):\n",
        "        class_type = int(self.targets[index])\n",
        "        path = self.filenamelist[index]\n",
        "        img_path = os.path.join(self.base_path,str(path).replace(\"\\\\\",\"/\"))\n",
        "        img = self.loader(img_path)       \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            class_type = self.target_transform(int(class_type))    \n",
        "\n",
        "        return img, class_type\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g9iPOtTKZzw",
        "colab_type": "text"
      },
      "source": [
        "**Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeOMn7XkKaCQ",
        "colab_type": "code",
        "outputId": "d1340559-c0ac-49a8-f080-6508775070a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Training settings\n",
        "parser = argparse.ArgumentParser(description='DeepSpeed_PytorchCustomLoader')\n",
        "parser.add_argument('--epochs', type=int, default=12, metavar='N',\n",
        "                    help='number of epochs to train (default: 10)')\n",
        "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
        "                    help='enables CUDA training')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreTrueAction(option_strings=['--no-cuda'], dest='no_cuda', nargs=0, const=True, default=False, type=None, choices=None, help='enables CUDA training', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtza3mlGCVMs",
        "colab_type": "text"
      },
      "source": [
        "**State of the art pytorch train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBElQfvJpCI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch, sum_loss):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        sum_loss += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return sum_loss\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4pypA2EKuX",
        "colab_type": "text"
      },
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4e72e255-ecd8-4fb7-b60a-10b833251363",
        "id": "L69FrvICJVfD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "args = parser.parse_args([])\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"Device is \", device)\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_dataset = MNISTCustom_Loader(\"/content/drive/My Drive/Colab Notebooks/Digit_Images/\",\n",
        "                                   \"/content/drive/My Drive/Colab Notebooks/Digit_Images/image_files.txt\" ,\n",
        "                                   \"/content/drive/My Drive/Colab Notebooks/Digit_Images/class.txt\",\n",
        "                                   transform=transforms.Compose([\n",
        "                                                                 transforms.ToTensor()  ,\n",
        "                                                                 transforms.Normalize((0.1307,), (0.3081,))                                       \n",
        "                                                                ]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1.0)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device is  cuda\n",
            "Loader Intialized Successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU1_fWmvL2Ec",
        "colab_type": "code",
        "outputId": "2321c539-3e61-44e9-dd9f-95f0a1028a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(\"Start time : \",datetime.now())\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    sum_loss = 0\n",
        "    sum_loss = train(args, model, device, train_loader, optimizer, epoch, sum_loss)\n",
        "    scheduler.step()\n",
        "    print(\"Epoch : \", epoch , \" Current_epoch_train_sum_loss : \" , sum_loss)\n",
        "print(\"End time : \",datetime.now())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start time :  2020-03-03 16:55:03.669965\n",
            "Epoch :  1  Current_epoch_train_sum_loss :  tensor(2.3463, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  2  Current_epoch_train_sum_loss :  tensor(5353339., device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  3  Current_epoch_train_sum_loss :  tensor(21434644., device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  4  Current_epoch_train_sum_loss :  tensor(3295686.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  5  Current_epoch_train_sum_loss :  tensor(1166831.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  6  Current_epoch_train_sum_loss :  tensor(1401051., device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  7  Current_epoch_train_sum_loss :  tensor(1125358.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  8  Current_epoch_train_sum_loss :  tensor(791744.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  9  Current_epoch_train_sum_loss :  tensor(723905.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  10  Current_epoch_train_sum_loss :  tensor(638756.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  11  Current_epoch_train_sum_loss :  tensor(504918.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  12  Current_epoch_train_sum_loss :  tensor(356201.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "End time :  2020-03-03 17:02:58.677167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUcL_IqMMoNJ",
        "colab_type": "text"
      },
      "source": [
        "**DeepSpeed Installation from  GITHUB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFjml6MbMo2G",
        "colab_type": "code",
        "outputId": "89589643-eef1-448d-b379-328587974c71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git init\n",
        "!git pull https://github.com/microsoft/DeepSpeed.git\n",
        "!./install.sh"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 546 (delta 15), reused 19 (delta 8), pack-reused 503\u001b[K\n",
            "Receiving objects: 100% (546/546), 406.13 KiB | 1.07 MiB/s, done.\n",
            "Resolving deltas: 100% (264/264), done.\n",
            "From https://github.com/microsoft/DeepSpeed\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Updating git hash/branch info\n",
            "git_hash = '7dbeba3'\n",
            "git_branch = 'master'\n",
            "No hostfile exists at /job/hostfile, installing locally\n",
            "Collecting torch==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 24kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/e6/a564eba563f7ff53aa7318ff6aaa5bd8385cbda39ed55ba471e95af27d19/torchvision-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 19.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow==6.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (6.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.28.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (5.4.8)\n",
            "Collecting tensorboardX==1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 60.5MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 12kB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (7.352.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (3.6.4)\n",
            "Collecting pytest-forked\n",
            "  Downloading https://files.pythonhosted.org/packages/03/1e/81235e1fcfed57a4e679d34794d60c01a1e9a29ef5b9844d797716111d80/pytest_forked-1.1.3-py2.py3-none-any.whl\n",
            "Collecting pre-commit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/42/3f6698ff1bf3297eb5ba586635ce1a4b93f9012b1a181e09fd874790bcbb/pre_commit-2.1.1-py2.py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 72.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.2->-r requirements.txt (line 1)) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.8->-r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.27.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (3.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (0.34.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 9)) (19.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 9)) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 9)) (45.1.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 9)) (8.2.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 9)) (1.8.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pre-commit->-r requirements.txt (line 11)) (1.5.0)\n",
            "Collecting toml\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/12/ced7105d2de62fa7c8fb5fce92cc4ce66b57c95fb875e9318dba7f8c5db0/toml-0.10.0-py2.py3-none-any.whl\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d9/ea9816aea31beeadccd03f1f8b625ecf8f645bd66744484d162d84803ce5/PyYAML-5.3.tar.gz (268kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 72.9MB/s \n",
            "\u001b[?25hCollecting cfgv>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/82/49913e721128ff16d6b7cf304f513de7bba698583b045dfb9c4b3bb2f467/cfgv-3.1.0-py2.py3-none-any.whl\n",
            "Collecting identify>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/08/ebd9cd04a6741b2cdf9a634170070d16085a38c2041e11a9b634c1cef623/identify-1.4.11-py2.py3-none-any.whl (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 15.3MB/s \n",
            "\u001b[?25hCollecting nodeenv>=0.11.1\n",
            "  Downloading https://files.pythonhosted.org/packages/08/43/86ff33286c83f7b5e8903c32db01fe122c5e8a9d8dc1067dcaa9be54a033/nodeenv-1.3.5-py2.py3-none-any.whl\n",
            "Collecting virtualenv>=15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/61/7506ddd79ef6f09beeefb81c4c55bf395a8ad96b33ff1c6b06e40f8aa101/virtualenv-20.0.7-py2.py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 46.6MB/s \n",
            "\u001b[?25hCollecting importlib-resources; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/45/51/5baae3dde223ff6b64aecaf4c191d2a2679f60abf1270b337823af668bf5/importlib_resources-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (2.8.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->-r requirements.txt (line 11)) (3.0.0)\n",
            "Collecting distlib<1,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/29/694a3a4d7c0e1aef76092e9167fbe372e0f7da055f5dcf4e1313ec21d96a/distlib-0.3.0.zip (571kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 67.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv>=15.2->pre-commit->-r requirements.txt (line 11)) (3.0.12)\n",
            "Collecting appdirs<2,>=1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pyyaml, distlib\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3-cp36-cp36m-linux_x86_64.whl size=44229 sha256=6023ba56a30d20855ca3b3175f2835d60fac8e0a84ef8488dc2b80b5b4d0ecf9\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/76/4d/a95b8dd7b452b69e8ed4f68b69e1b55e12c9c9624dd962b191\n",
            "  Building wheel for distlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distlib: filename=distlib-0.3.0-cp36-none-any.whl size=340429 sha256=d070574444e9353bace244608d7085f442ba118e7b9b874a978544c4c3368895\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/e8/db/c73dae4867666e89ba3cfbc4b5c092446f0e584eda6f409cbb\n",
            "Successfully built pyyaml distlib\n",
            "Installing collected packages: torch, torchvision, tensorboardX, tensorflow-gpu, pytest-forked, toml, pyyaml, cfgv, identify, nodeenv, importlib-resources, distlib, appdirs, virtualenv, pre-commit\n",
            "  Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "  Found existing installation: torchvision 0.5.0\n",
            "    Uninstalling torchvision-0.5.0:\n",
            "      Successfully uninstalled torchvision-0.5.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed appdirs-1.4.3 cfgv-3.1.0 distlib-0.3.0 identify-1.4.11 importlib-resources-1.2.0 nodeenv-1.3.5 pre-commit-2.1.1 pytest-forked-1.1.3 pyyaml-5.3 tensorboardX-1.8 tensorflow-gpu-1.15.2 toml-0.10.0 torch-1.2.0 torchvision-0.4.0 virtualenv-20.0.7\n",
            "Checking out sub-module(s)\n",
            "Submodule 'DeepSpeedExamples' (https://github.com/microsoft/DeepSpeedExamples) registered for path 'DeepSpeedExamples'\n",
            "Submodule 'third_party/apex' (https://github.com/NVIDIA/apex.git) registered for path 'third_party/apex'\n",
            "Cloning into '/content/DeepSpeedExamples'...\n",
            "Cloning into '/content/third_party/apex'...\n",
            "Submodule path 'DeepSpeedExamples': checked out 'e0d2d7f4a86f03612bc0a210a5e4dbcc798b48a6'\n",
            "Submodule path 'third_party/apex': checked out '880ab925bce9f817a93988b021e12db5f67f7787'\n",
            "Building apex wheel\n",
            "torch.__version__  =  1.2.0\n",
            "setup.py:33: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "  warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "Compiling cuda extensions with\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n",
            "from /usr/local/cuda/bin\n",
            "\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/apex\n",
            "copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "running build_ext\n",
            "building 'apex_C' extension\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/csrc\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'amp_C' extension\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'fused_adam_cuda' extension\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'syncbn' extension\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'fused_layer_norm_cuda' extension\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "installing to build/bdist.linux-x86_64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/wheel\n",
            "creating build/bdist.linux-x86_64/wheel/apex\n",
            "creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "creating build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "copying build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "creating apex.egg-info\n",
            "writing apex.egg-info/PKG-INFO\n",
            "writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "writing top-level names to apex.egg-info/top_level.txt\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.6.egg-info\n",
            "running install_scripts\n",
            "adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
            "creating 'dist/apex-0.1-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "adding 'amp_C.cpython-36m-x86_64-linux-gnu.so'\n",
            "adding 'apex_C.cpython-36m-x86_64-linux-gnu.so'\n",
            "adding 'fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "adding 'fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "adding 'syncbn.cpython-36m-x86_64-linux-gnu.so'\n",
            "adding 'apex/__init__.py'\n",
            "adding 'apex/RNN/RNNBackend.py'\n",
            "adding 'apex/RNN/__init__.py'\n",
            "adding 'apex/RNN/cells.py'\n",
            "adding 'apex/RNN/models.py'\n",
            "adding 'apex/amp/__init__.py'\n",
            "adding 'apex/amp/__version__.py'\n",
            "adding 'apex/amp/_amp_state.py'\n",
            "adding 'apex/amp/_initialize.py'\n",
            "adding 'apex/amp/_process_optimizer.py'\n",
            "adding 'apex/amp/amp.py'\n",
            "adding 'apex/amp/compat.py'\n",
            "adding 'apex/amp/frontend.py'\n",
            "adding 'apex/amp/handle.py'\n",
            "adding 'apex/amp/opt.py'\n",
            "adding 'apex/amp/rnn_compat.py'\n",
            "adding 'apex/amp/scaler.py'\n",
            "adding 'apex/amp/utils.py'\n",
            "adding 'apex/amp/wrap.py'\n",
            "adding 'apex/amp/lists/__init__.py'\n",
            "adding 'apex/amp/lists/functional_overrides.py'\n",
            "adding 'apex/amp/lists/tensor_overrides.py'\n",
            "adding 'apex/amp/lists/torch_overrides.py'\n",
            "adding 'apex/fp16_utils/__init__.py'\n",
            "adding 'apex/fp16_utils/fp16_optimizer.py'\n",
            "adding 'apex/fp16_utils/fp16util.py'\n",
            "adding 'apex/fp16_utils/loss_scaler.py'\n",
            "adding 'apex/multi_tensor_apply/__init__.py'\n",
            "adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
            "adding 'apex/normalization/__init__.py'\n",
            "adding 'apex/normalization/fused_layer_norm.py'\n",
            "adding 'apex/optimizers/__init__.py'\n",
            "adding 'apex/optimizers/fp16_optimizer.py'\n",
            "adding 'apex/optimizers/fused_adam.py'\n",
            "adding 'apex/parallel/LARC.py'\n",
            "adding 'apex/parallel/__init__.py'\n",
            "adding 'apex/parallel/distributed.py'\n",
            "adding 'apex/parallel/multiproc.py'\n",
            "adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
            "adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
            "adding 'apex/parallel/sync_batchnorm.py'\n",
            "adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
            "adding 'apex/pyprof/__init__.py'\n",
            "adding 'apex/pyprof/nvtx/__init__.py'\n",
            "adding 'apex/pyprof/nvtx/nvmarker.py'\n",
            "adding 'apex/pyprof/parse/__init__.py'\n",
            "adding 'apex/pyprof/parse/__main__.py'\n",
            "adding 'apex/pyprof/parse/db.py'\n",
            "adding 'apex/pyprof/parse/kernel.py'\n",
            "adding 'apex/pyprof/parse/nvvp.py'\n",
            "adding 'apex/pyprof/parse/parse.py'\n",
            "adding 'apex/pyprof/prof/__init__.py'\n",
            "adding 'apex/pyprof/prof/__main__.py'\n",
            "adding 'apex/pyprof/prof/activation.py'\n",
            "adding 'apex/pyprof/prof/base.py'\n",
            "adding 'apex/pyprof/prof/blas.py'\n",
            "adding 'apex/pyprof/prof/conv.py'\n",
            "adding 'apex/pyprof/prof/convert.py'\n",
            "adding 'apex/pyprof/prof/data.py'\n",
            "adding 'apex/pyprof/prof/dropout.py'\n",
            "adding 'apex/pyprof/prof/embedding.py'\n",
            "adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
            "adding 'apex/pyprof/prof/linear.py'\n",
            "adding 'apex/pyprof/prof/loss.py'\n",
            "adding 'apex/pyprof/prof/misc.py'\n",
            "adding 'apex/pyprof/prof/normalization.py'\n",
            "adding 'apex/pyprof/prof/optim.py'\n",
            "adding 'apex/pyprof/prof/output.py'\n",
            "adding 'apex/pyprof/prof/pointwise.py'\n",
            "adding 'apex/pyprof/prof/pooling.py'\n",
            "adding 'apex/pyprof/prof/prof.py'\n",
            "adding 'apex/pyprof/prof/randomSample.py'\n",
            "adding 'apex/pyprof/prof/recurrentCell.py'\n",
            "adding 'apex/pyprof/prof/reduction.py'\n",
            "adding 'apex/pyprof/prof/softmax.py'\n",
            "adding 'apex/pyprof/prof/usage.py'\n",
            "adding 'apex/pyprof/prof/utility.py'\n",
            "adding 'apex/reparameterization/__init__.py'\n",
            "adding 'apex/reparameterization/reparameterization.py'\n",
            "adding 'apex/reparameterization/weight_norm.py'\n",
            "adding 'apex-0.1.dist-info/LICENSE'\n",
            "adding 'apex-0.1.dist-info/METADATA'\n",
            "adding 'apex-0.1.dist-info/WHEEL'\n",
            "adding 'apex-0.1.dist-info/top_level.txt'\n",
            "adding 'apex-0.1.dist-info/RECORD'\n",
            "removing build/bdist.linux-x86_64/wheel\n",
            "/content\n",
            "Installing apex locally so that deepspeed will build\n",
            "\u001b[33mWARNING: Skipping apex as it is not installed.\u001b[0m\n",
            "Processing ./third_party/apex/dist/apex-0.1-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: apex\n",
            "Successfully installed apex-0.1\n",
            "Building deepspeed wheel\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/deepspeed\n",
            "copying deepspeed/__init__.py -> build/lib.linux-x86_64-3.6/deepspeed\n",
            "copying deepspeed/git_version_info.py -> build/lib.linux-x86_64-3.6/deepspeed\n",
            "creating build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/fp16_unfused_optimizer.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/loss_scaler.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_run.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_config.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_timer.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_constants.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_dataloader.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_utils.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_light.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_zero_optimizer.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_lr_schedules.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/__init__.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_fused_lamb.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_launch.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "copying deepspeed/pt/deepspeed_csr_tensor.py -> build/lib.linux-x86_64-3.6/deepspeed/pt\n",
            "running build_ext\n",
            "building 'fused_lamb_cuda' extension\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/csrc\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_lamb_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/fused_lamb_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_lamb_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_lamb_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/fused_lamb_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_lamb_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "csrc/fused_lamb_cuda_kernel.cu(34): warning: function \"<unnamed>::error\" was referenced but not defined\n",
            "\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/fused_lamb_cuda.o build/temp.linux-x86_64-3.6/csrc/fused_lamb_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_lamb_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "running build_scripts\n",
            "creating build/scripts-3.6\n",
            "copying and adjusting bin/deepspeed -> build/scripts-3.6\n",
            "copying and adjusting bin/deepspeed.pt -> build/scripts-3.6\n",
            "copying and adjusting bin/ds -> build/scripts-3.6\n",
            "copying bin/ds_ssh -> build/scripts-3.6\n",
            "changing mode of build/scripts-3.6/deepspeed from 644 to 755\n",
            "changing mode of build/scripts-3.6/deepspeed.pt from 644 to 755\n",
            "changing mode of build/scripts-3.6/ds from 644 to 755\n",
            "installing to build/bdist.linux-x86_64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/wheel\n",
            "creating build/bdist.linux-x86_64/wheel/deepspeed\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed\n",
            "creating build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/fp16_unfused_optimizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/loss_scaler.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_run.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_timer.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_dataloader.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_light.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_zero_optimizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_lr_schedules.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_launch.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/pt/deepspeed_csr_tensor.py -> build/bdist.linux-x86_64/wheel/deepspeed/pt\n",
            "copying build/lib.linux-x86_64-3.6/deepspeed/git_version_info.py -> build/bdist.linux-x86_64/wheel/deepspeed\n",
            "copying build/lib.linux-x86_64-3.6/fused_lamb_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "creating deepspeed.egg-info\n",
            "writing deepspeed.egg-info/PKG-INFO\n",
            "writing dependency_links to deepspeed.egg-info/dependency_links.txt\n",
            "writing top-level names to deepspeed.egg-info/top_level.txt\n",
            "writing manifest file 'deepspeed.egg-info/SOURCES.txt'\n",
            "writing manifest file 'deepspeed.egg-info/SOURCES.txt'\n",
            "Copying deepspeed.egg-info to build/bdist.linux-x86_64/wheel/deepspeed-0.1.0-py3.6.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.linux-x86_64/wheel/deepspeed-0.1.0.data\n",
            "creating build/bdist.linux-x86_64/wheel/deepspeed-0.1.0.data/scripts\n",
            "copying build/scripts-3.6/deepspeed.pt -> build/bdist.linux-x86_64/wheel/deepspeed-0.1.0.data/scripts\n",
            "copying build/scripts-3.6/ds -> build/bdist.linux-x86_64/wheel/deepspeed-0.1.0.data/scripts\n",
            "copying build/scripts-3.6/deepspeed -> build/bdist.linux-x86_64/wheel/deepspeed-0.1.0.data/scripts\n",
            "copying build/scripts-3.6/ds_ssh -> build/bdist.linux-x86_64/wheel/deepspeed-0.1.0.data/scripts\n",
            "changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.1.0.data/scripts/deepspeed.pt to 755\n",
            "changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.1.0.data/scripts/ds to 755\n",
            "changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.1.0.data/scripts/deepspeed to 755\n",
            "changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.1.0.data/scripts/ds_ssh to 755\n",
            "adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "creating build/bdist.linux-x86_64/wheel/deepspeed-0.1.0.dist-info/WHEEL\n",
            "creating 'dist/deepspeed-0.1.0-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "adding 'fused_lamb_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "adding 'deepspeed/__init__.py'\n",
            "adding 'deepspeed/git_version_info.py'\n",
            "adding 'deepspeed/pt/__init__.py'\n",
            "adding 'deepspeed/pt/deepspeed_config.py'\n",
            "adding 'deepspeed/pt/deepspeed_constants.py'\n",
            "adding 'deepspeed/pt/deepspeed_csr_tensor.py'\n",
            "adding 'deepspeed/pt/deepspeed_dataloader.py'\n",
            "adding 'deepspeed/pt/deepspeed_fused_lamb.py'\n",
            "adding 'deepspeed/pt/deepspeed_launch.py'\n",
            "adding 'deepspeed/pt/deepspeed_light.py'\n",
            "adding 'deepspeed/pt/deepspeed_lr_schedules.py'\n",
            "adding 'deepspeed/pt/deepspeed_run.py'\n",
            "adding 'deepspeed/pt/deepspeed_timer.py'\n",
            "adding 'deepspeed/pt/deepspeed_utils.py'\n",
            "adding 'deepspeed/pt/deepspeed_zero_optimizer.py'\n",
            "adding 'deepspeed/pt/fp16_optimizer.py'\n",
            "adding 'deepspeed/pt/fp16_unfused_optimizer.py'\n",
            "adding 'deepspeed/pt/loss_scaler.py'\n",
            "adding 'deepspeed-0.1.0.data/scripts/deepspeed'\n",
            "adding 'deepspeed-0.1.0.data/scripts/deepspeed.pt'\n",
            "adding 'deepspeed-0.1.0.data/scripts/ds'\n",
            "adding 'deepspeed-0.1.0.data/scripts/ds_ssh'\n",
            "adding 'deepspeed-0.1.0.dist-info/LICENSE'\n",
            "adding 'deepspeed-0.1.0.dist-info/METADATA'\n",
            "adding 'deepspeed-0.1.0.dist-info/WHEEL'\n",
            "adding 'deepspeed-0.1.0.dist-info/top_level.txt'\n",
            "adding 'deepspeed-0.1.0.dist-info/RECORD'\n",
            "removing build/bdist.linux-x86_64/wheel\n",
            "Installing deepspeed\n",
            "\u001b[33mWARNING: Skipping deepspeed as it is not installed.\u001b[0m\n",
            "Processing ./dist/deepspeed-0.1.0-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: deepspeed\n",
            "Successfully installed deepspeed-0.1.0\n",
            "deepspeed info: 0.1.0 master 7dbeba3\n",
            "Installation is successful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ssIz4ujpTaI",
        "colab_type": "text"
      },
      "source": [
        "**Import DeepSpeed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC8cF88ApRwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b291b98-3abd-4eda-83fd-b61fb469c888"
      },
      "source": [
        "import deepspeed"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi3yAxZwSTDG",
        "colab_type": "text"
      },
      "source": [
        "**DeepSpeed Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QyIrb64STZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_with_deepsped(args, model_engine, device, train_loader,  epoch, sum_loss):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        #- deepspeed\n",
        "        data, target = data[0].to(model_engine.local_rank) , target[0].to(model_engine.local_rank)\n",
        "        #- - deepspeed\n",
        "        data , target = Variable(data.unsqueeze(0)), Variable(target.unsqueeze(0))\n",
        "        \n",
        "        #- deepspeed\n",
        "        output = model_engine(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        sum_loss += loss\n",
        "        #- deepspeed , runs backpropagation\n",
        "        model_engine.backward(loss)\n",
        "        #- deepspeed , weight update - deepspeed\n",
        "        model_engine.step()\n",
        "        return sum_loss\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcq0wREMTC9w",
        "colab_type": "text"
      },
      "source": [
        "**Deepspeed additional Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLpoggT3TDOe",
        "colab_type": "code",
        "outputId": "e3545f08-652b-4ca9-f27e-4f173fc09f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "parser.add_argument('--local_rank', type=int, default=0,\n",
        "                    help='local rank passed from distributed launcher')\n",
        "\n",
        "parser.add_argument('--deepspeed_config', default=\"/content/drive/My Drive/Colab Notebooks/Casme/ds_config.json\", type=str,\n",
        "                    help='deepspeed config file')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--deepspeed_config'], dest='deepspeed_config', nargs=None, const=None, default='/content/drive/My Drive/Colab Notebooks/Casme/ds_config.json', type=<class 'str'>, choices=None, help='deepspeed config file', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVvWmt41SpUt",
        "colab_type": "text"
      },
      "source": [
        "**DeepSpeed Main**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY_QeCj5UeRr",
        "colab_type": "code",
        "outputId": "4ba64e63-601b-4f6a-a1ce-723a2b7df099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "args = parser.parse_args([])\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"Device is \", device)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_dataset = MNISTCustom_Loader(\"/content/drive/My Drive/Colab Notebooks/Digit_Images/\",\n",
        "                                   \"/content/drive/My Drive/Colab Notebooks/Digit_Images/image_files.txt\" ,\n",
        "                                   \"/content/drive/My Drive/Colab Notebooks/Digit_Images/class.txt\",\n",
        "                                   transform=transforms.Compose([\n",
        "                                                                 transforms.ToTensor()  ,\n",
        "                                                                 transforms.Normalize((0.1307,), (0.3081,))                                       \n",
        "                                                                ]))\n",
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "# Initialize DeepSpeed to use the following features\n",
        "# 1) Distributed model\n",
        "# 2) Distributed data loader\n",
        "# 3) DeepSpeed optimizer\n",
        "\n",
        "os.environ[\"RANK\"] = \"0\"\n",
        "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
        "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "os.environ[\"MASTER_PORT\"] = \"6000\"\n",
        "\n",
        "model_engine, optimizer, train_loader, __ = deepspeed.initialize(args=args, model=model, model_parameters=model.parameters(), training_data=train_dataset)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device is  cuda\n",
            "Loader Intialized Successfully\n",
            "DeepSpeed info: version=0.1.0, git-hash=7e3509b, git-branch=master\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO 2020-03-03 17:07:55] Set device to local rank 0 within node.\n",
            "[INFO 2020-03-03 17:07:55] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[INFO 2020-03-03 17:07:55] DeepSpeed Basic Optimizer = FusedAdam (\n",
            "Parameter Group 0\n",
            "    betas: [0.8, 0.999]\n",
            "    bias_correction: True\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    max_grad_norm: 0.0\n",
            "    weight_decay: 3e-07\n",
            ")\n",
            "[WARNING 2020-03-03 17:07:55] DeepSpeed using client LR scheduler\n",
            "[INFO 2020-03-03 17:07:55] DeepSpeed LR Scheduler = None\n",
            "[INFO 2020-03-03 17:07:55] rank:0 step=0, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " After Train batch 28 micro_batch 28 and grad_acc 1\n",
            "1 1\n",
            "DeepSpeedLight configuration:\n",
            "  allgather_size ............... 500000000\n",
            "  allreduce_always_fp32 ........ False\n",
            "  disable_allgather ............ False\n",
            "  dump_state ................... False\n",
            "  dynamic_loss_scale_args ...... None\n",
            "  fp16_enabled ................. False\n",
            "  global_rank .................. 0\n",
            "  gradient_accumulation_steps .. 1\n",
            "  gradient_clipping ............ 0.0\n",
            "  initial_dynamic_scale ........ 4294967296\n",
            "  loss_scale ................... 0\n",
            "  optimizer_legacy_fusion ...... True\n",
            "  optimizer_name ............... adam\n",
            "  optimizer_params ............. {'lr': 0.001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n",
            "  prescale_gradients ........... False\n",
            "  scheduler_name ............... None\n",
            "  scheduler_params ............. None\n",
            "  sparse_gradients_enabled ..... False\n",
            "  steps_per_print .............. 2000\n",
            "  tensorboard_enabled .......... False\n",
            "  tensorboard_job_name ......... DeepSpeedJobName\n",
            "  tensorboard_output_path ...... \n",
            "  train_batch_size ............. 28\n",
            "  train_micro_batch_size_per_gpu  28\n",
            "  wall_clock_breakdown ......... False\n",
            "  world_size ................... 1\n",
            "  zero_enabled ................. False\n",
            "  json = {\n",
            "    \"optimizer\":{\n",
            "        \"params\":{\n",
            "            \"betas\":[\n",
            "                0.8,\n",
            "                0.999\n",
            "            ],\n",
            "            \"eps\":1e-08,\n",
            "            \"lr\":0.001,\n",
            "            \"weight_decay\":3e-07\n",
            "        },\n",
            "        \"type\":\"Adam\"\n",
            "    },\n",
            "    \"steps_per_print\":2000,\n",
            "    \"train_batch_size\":28,\n",
            "    \"wall_clock_breakdown\":false\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_qxrOX5pDkK",
        "colab_type": "code",
        "outputId": "94d001f6-9917-4517-b83a-9d525f77e4e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(\"Start time : \",datetime.now())\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    sum_loss = 0\n",
        "    sum_loss = train_with_deepsped(args, model_engine, device, train_loader, epoch, sum_loss)\n",
        "    print(\"Epoch : \", epoch , \" Current_epoch_train_sum_loss : \", sum_loss )\n",
        "\n",
        "print(\"End time : \",datetime.now())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start time :  2020-03-03 17:08:00.698877\n",
            "Epoch :  1  Current_epoch_train_sum_loss :  tensor(2.5222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  2  Current_epoch_train_sum_loss :  tensor(1.5162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  3  Current_epoch_train_sum_loss :  tensor(0.0890, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  4  Current_epoch_train_sum_loss :  tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  5  Current_epoch_train_sum_loss :  tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  6  Current_epoch_train_sum_loss :  tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  7  Current_epoch_train_sum_loss :  tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  8  Current_epoch_train_sum_loss :  tensor(5.7220e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  9  Current_epoch_train_sum_loss :  tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  10  Current_epoch_train_sum_loss :  tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  11  Current_epoch_train_sum_loss :  tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  12  Current_epoch_train_sum_loss :  tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
            "End time :  2020-03-03 17:08:04.989139\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}